# Simple workflow for deploying static content to GitHub Pages
name: Scrape information from cinemas and store it on the database

on:
    # Runs on pushes targeting the default branch
    push:
        branches: ['main']
    # Run every day at 7.47 in the morning
    schedule:
        - cron: '47 7 * * *'

    # Allows you to run this workflow manually from the Actions tab
    workflow_dispatch:

# Allow one concurrent deployment
concurrency:
    group: 'scrape'
    cancel-in-progress: true

jobs:
    scraper:
        runs-on: ubuntu-latest
        env:
            API_KEY: ${{ secrets.PROD_API_KEY }}
            SUPABASE_PROJECT_ID: ${{ secrets.SUPABASE_PROJECT_ID }}
        steps:
            - name: Checkout
              uses: actions/checkout@v4
            - name: Set up Node
              uses: actions/setup-node@v4
              with:
                  node-version: lts/*
                  cache: 'npm'
            # Restore node_modules cache
            - name: Cache node_modules
              id: node-modules-cache
              uses: actions/cache@v4
              with:
                  path: node_modules
                  key: ${{ runner.os }}-node-modules-${{ hashFiles('**/package-lock.json') }}
                  restore-keys: |
                      ${{ runner.os }}-node-modules-

            # Install dependencies ONLY if cache miss
            - name: Install dependencies
              if: steps.node-modules-cache.outputs.cache-hit != 'true'
              run: npm ci
            - name: Install dependencies
              run: npm ci
            - name: Run Scraping
              run: npm run get_data
